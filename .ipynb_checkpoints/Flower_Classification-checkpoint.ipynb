{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch # import pytorch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch import optim, nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import copy\n",
    "import seaborn as sns\n",
    "print(torch.__version__) # find out the version of pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1f66c881432a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#find out the train and test data directories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/flower_data/flower_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input'"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../input'))\n",
    "#find out the train and test data directories\n",
    "print(os.listdir('../input/flower_data/flower_data'))\n",
    "print(os.listdir('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the image (scaling, flipping and normalisation)\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(255),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../input/flower_data/flower_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid']}\n",
    "\n",
    "#info about no. of datapoints\n",
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the data loaders\n",
    "batch_size = 64\n",
    "# trainLoader = data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=False)\n",
    "# testLoader = data.DataLoader(image_datasets['valid'], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders = {x: data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) \n",
    "                   for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.numpy().transpose((1, 2, 0))\n",
    "    else:\n",
    "        image = np.array(image).transpose((1, 2, 0))\n",
    "    # denormalisation\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    # plot\n",
    "    fig, Xaxis = plt.subplots(1, 1, figsize=(9, 9))\n",
    "    %matplotlib inline\n",
    "    plt.imshow(image)\n",
    "    Xaxis.axis('off') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grid from batch (for training data)\n",
    "# This grid shows the images which are present in 1 batch\n",
    "images, _ = next(iter(dataloaders['train']))\n",
    "trainGrid = torchvision.utils.make_grid(images, nrow=8)\n",
    "\n",
    "show(trainGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grid from batch (for validation/test data)\n",
    "images, _ = next(iter(dataloaders['valid']))\n",
    "testGrid = torchvision.utils.make_grid(images, nrow=8)\n",
    "\n",
    "show(testGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = image_datasets['train'].classes\n",
    "\n",
    "#Get labels to class names from json file\n",
    "import json\n",
    "with open('../input/cat_to_name.json', 'r') as f:\n",
    "    labelToName = json.load(f)\n",
    "\n",
    "# print(image_datasets['train'].classes)\n",
    "labelToName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning - ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build and train your network\n",
    "model = models.densenet161(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    \n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(nn.Linear(2208, 1024),\n",
    "                                 nn.ReLU(),\n",
    "#                                  nn.Dropout(p=0.1),\n",
    "#                                  nn.Linear(4096, 2048),\n",
    "#                                  nn.ReLU(),\n",
    "#                                  nn.Dropout(p=0.1),\n",
    "#                                  nn.Linear(2048, 1024),\n",
    "#                                  nn.ReLU(),\n",
    "                                 nn.Dropout(p=0.1),\n",
    "                                 nn.Linear(1024, 102),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "  \n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            \n",
    "            steps += 1\n",
    "            \n",
    "            # Flatten images into a 784 long vector\n",
    "            #images.resize_(images.size()[0], -1)\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()\n",
    "\n",
    "def validation(model, testloader, criterion):\n",
    "  \n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        #images = images.resize_(images.size()[0], -1)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment these two lines when you want to re-train\n",
    "\n",
    "train(model, dataloaders['train'], dataloaders['valid'], criterion, optimizer, epochs=12)\n",
    "validation(model, dataloaders['valid'], criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the checkpoint\n",
    "'''\n",
    "checkpoint = {'input_size': 1024,\n",
    "              'output_size': 102,\n",
    "              'epochs': 12,\n",
    "              'classifier': model.classifier,\n",
    "              'optimizer_state': optimizer.state_dict(),\n",
    "              'mapping': image_datasets['train'].class_to_idx,\n",
    "              'state_dict': model.state_dict()}\n",
    "'''\n",
    "# Save the checkpoint \n",
    "#torch.save(checkpoint, 'checkpoint.pth')\n",
    "idx_to_class = {}\n",
    "for x in image_datasets['train'].class_to_idx:\n",
    "    idx_to_class[image_datasets['train'].class_to_idx[x]] = labelToName[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    print('Loading checkpoint...')\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "    model = models.densenet121(pretrained=True)\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.optimizer_state = checkpoint['optimizer_state']\n",
    "    model.mapping = checkpoint['mapping']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print('Done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.listdir('../input/checkpoint'))\n",
    "model = load_checkpoint('checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Processing\n",
    "\n",
    "def process_image(image):\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    if img.size[0] > img.size[1]:  #resizing the image\n",
    "        img.thumbnail((10000, 256))\n",
    "    else:\n",
    "        img.thumbnail((256, 10000))\n",
    "        \n",
    "    #crop the image\n",
    "    left_margin = (img.width-224)/2\n",
    "    bottom_margin = (img.height - 224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    top_margin = bottom_margin + 224\n",
    "    img = img.crop((left_margin, bottom_margin, right_margin, top_margin))\n",
    "    \n",
    "    #normalising\n",
    "    img = np.array(img)/255\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = (img - mean)/std\n",
    "    \n",
    "    #moving color channels to first dimention as expected by pytorch\n",
    "    img = img.transpose((2,0,1))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    # PyTorch tensors assume the color channel is first\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = data_dir + '/train/61/image_06281.jpg'\n",
    "img = process_image(image_path)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the class \n",
    "\n",
    "def predict(image_path, model, topk=5):\n",
    "    \n",
    "    print('Prediction on Flower Classification starts')\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    \n",
    "    idx_to_class = {i: k for k, i in model.mapping.items()}\n",
    "    \n",
    "    #opening the image\n",
    "    with Image.open(image_path) as image:\n",
    "        image = process_image(image)\n",
    "        \n",
    "    #switching it to float tensor\n",
    "    image = torch.FloatTensor([image])\n",
    "    \n",
    "    #feeding it through the model\n",
    "    output = model.forward(image)\n",
    "    \n",
    "    #to determine the topk probability and labels\n",
    "    topk_prob, topk_labels = torch.topk(output, topk)\n",
    "    \n",
    "    #taking exp() of image to cancel out the LogSoftmax\n",
    "    topk_prob = topk_prob.exp()\n",
    "    \n",
    "    #assemble the lists\n",
    "    topk_prob_arr = topk_prob.data.numpy()[0]\n",
    "    topk_indexes_list = topk_labels.data.numpy()[0].tolist()\n",
    "    print('topk_indexes_list', topk_indexes_list)\n",
    "    print(topk_indexes_list[0])\n",
    "    \n",
    "    topk_labels_list = [idx_to_class[x] for x in topk_indexes_list]\n",
    "    print('topk_labels_list: ', topk_labels_list)\n",
    "    \n",
    "    topk_class_arr = [labelToName[str(x)] for x in topk_labels_list]\n",
    "    print('topk_prob_arr: ', topk_prob_arr)\n",
    "    print('topk_class_arr: ', topk_class_arr)\n",
    "    print('Done')\n",
    "    \n",
    "    return topk_prob_arr, topk_class_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final SANITY Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(image_path, model):\n",
    "    \n",
    "    plt.figure(figsize = (6, 10))\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    \n",
    "    #setting the title\n",
    "    flower_num = image_path.split('/')[-2]\n",
    "    print(flower_num)\n",
    "    title_ = labelToName[flower_num]\n",
    "    \n",
    "    #plotting flower\n",
    "    img = process_image(image_path)\n",
    "    imshow(img, ax, title = title_);\n",
    "    \n",
    "    #to make prediction\n",
    "    probs, flowers = predict(image_path, model)\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    sns.barplot(x=probs, y=flowers, color=sns.color_palette()[0]);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = image_path\n",
    "sanity_check(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which picks number of random images from the provided directory\n",
    "def getImages(numImages, dataDir, shuffle=True):\n",
    "    data = datasets.ImageFolder(dataDir, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    idx = indices[:]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, shuffle=shuffle\n",
    "                    ,batch_size=numImages)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference step\n",
    "test_dir = \"../input/flower_data/flower_data/train\"\n",
    "to_pil = transforms.ToPILImage()\n",
    "images,  labels = getImages(5,test_dir)\n",
    "print(labels)\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    index = predictImages(image)\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    res = int(labels[ii]) == index\n",
    "    sub.set_title(str(idx_to_class[index]) + \":\" + str(res))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
